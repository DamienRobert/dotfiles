cf 
- http://www.madore.org/~david/weblog/2013-01-16-grands-nombres.html#d.2013-01-16.2104

- forum sciences.maths:18969

x+y est de niveau 1
x*y de niveau 2
x^y de niveau 3

Ackerman de niveau w_0
Ackerman itérée: 
  AA(x,y)= A(AA(x-1,y),y) de niveau omega+1
  AAA(x,y)=AA(AAA(x-1,y),y) de niveau omega+2

Les flêches de Conway:
x->y->n c'est [n](x,y), donc ça donne Ackerman
x->y->z->t ça donne AAAAAA, donc de niveau omega*2
                    t fois
Flêche de longeur 2+n de niveau omega*n
Donc avec un nombre de flêches variables on obtient omega^2

Ackerman à plusieurs variables: n+1 variables donne omega^n
A(x,y,z)=A(A(x-1,y,z),y-1,z)
A(x,y,z,t)=A(A(x-1,y,z,t),y-1,z,t)
-> omega^omega en faisant varier le nombre de variables

La fonction de Friedman's (sur les sous-blocs) est d'ordre omega^omega
aussi (voir plus bas)

Fonction de Goodstein: 
Pour G1 on écrit X_0 = b + X_1 récursivement
Pour G2 on écrit X_0= b X_1 + X_2 récursivement
Pour G3 on écrit X_0 = b^X_1*X_2+X_3 récursivement
Pour G4 on écrit X_0 = b^^X_1^X_2*X_3+X_4 récursivement...
puis on change les b en b+1, et on retranche 1, on recommence jusqu'à tomber sur 0.
Alors G2 est d'ordre omega, G3 d'ordre epsilon_0 et (conjecture) G_n est d'ordre \phi_{n-2}(0) où \phi est la fonction de Veblen, ie G_4 est d'ordre \eta_0, ...
L'hydre de Kirby-Paris est d'ordre \epsilon_0

La fonction Tree, d'ordre entre \Gamma_0 (Feferman-Schütte et le petit
ordinal de Weblen)
  Tree(n) est le (plus petit) nombre tel que pour toute suite d'arbres T_1,
  ..., T_f(n), chaque arbre étant étiqueté par un élément dans {1, ..., n},
  et l'arbre T_i ayant au plus i sommets, alors il y a forcément deux arbres
  T_a et T_b avec T_a <= T_b (ie on peut mapper homéorphiquement T_a dans T_b
  en préservant les étiquettes).

  The TREE sequence begins TREE(1) = 1, TREE(2) = 3, then suddenly TREE(3)
  explodes to a value so enormously large that many other "large"
  combinatorial constants, such as Friedman's n(4),[*] are extremely small
  by comparison. A lower bound for n(4), and hence an extremely weak
  lower bound for TREE(3), is A(A(...A(1)...)), where the number of As is
  A(187196),[2] and A() is a version of Ackermann's function: A(x) = 2↑^{x-1}x
  in Knuth's up-arrow notation. Graham's number, for example, is
  approximately A^{64}(4) which is much smaller than the lower bound
  A^{A(187196)}(1). It can be shown that the growth-rate of the function TREE
  exceeds that of the function fΓ0 in the fast-growing hierarchy, where Γ0
  is the Feferman–Schütte ordinal.

  ^* n(k) is defined as the length of the longest possible sequence that
  can be constructed with a k-letter alphabet such that no block of letters
  x_i,...,x_2i is a subsequence of any later block x_j,...,x_2j.[3] n(1) = 3,
  n(2) = 11 and n(3) > 2↑^{7197}158386.
  (cf http://mathoverflow.net/questions/163007/applications-of-really-large-numbers,
  http://googology.wikia.com/wiki/Block_subsequence_theorem
  Friedman has demonstrated that the growth rate of the n function lies asymptotically between f_{ω^ω}(n) and f_{ω^ω+1}(n)
  )

La même sur les graphes, d'ordre le collapse de \Omega_\Omega
  http://en.wikipedia.org/wiki/Robertson%E2%80%93Seymour_theorem
  Theorem: For every positive integer n, there is an integer m so large
  that if G1, ..., Gm is a sequence of finite undirected graphs, where each
  Gi has size at most n+i, then Gj ≤ Gk for some j < k.
L'hydre de David, qui suivant la stratégie se comporte comme \Gamma_0 ou
comme le collapse de \Omega^\Omega^...^\Omega (ordinal de
Bachman-Horward); l'hydre de Bucholz se comporte comme le collapse de
\Omega_\Omega: http://googology.wikia.com/wiki/Buchholz_hydras

Les busy beavers sur les machines de Turing dont une théorie prouve
qu'elles s'arrêtent en moins de n caractères (d'ordre la puissance ordinale
de la théorie)

http://googology.wikia.com/wiki/Rayo%27s_number
The smallest positive integer bigger than any finite positive integer named by an expression in the language of first order set theory with a googol symbols or less
(pas du tout calculable, si on remplace first order set theory par first
order arithmetic theory on a w_1^CK, et 
http://googology.wikia.com/wiki/Xi_function est d'ordre le point fixe de
a->w_a^CK, mais plus petit que la fonction de Rayo)

- http://mathoverflow.net/questions/108949/various-definitions-of-recursion-from-ordinal-machines

------------------------------------------------
Thread de yaf.maths:1048:
-> yaf.maths:1055

#> Toi, tu n'avais pas le droit de répondre.  Ceci dit, je m'attendais à
#> mieux de ta part. :-]
#
#Oui, c'est un peu décevant, une version d'Ackerman, soit seulement
#une croissance de w_0...
#
#Je propose quelques examples plus intéressants:
#- f(n)=n->n->..->n avec les notations de Conway (de croissance w_0^2),
#- Les suites de Goodstein ou des versions à base de l'hydre (epsilon_0)
#- La suite TREE (de croissance l'ordre)

Oui, c'est un peu décevant, une version d'Ackerman...

Quitte à m'auto-usurper, j'aurais au moins proposé le nombre suivant:
soit f(n) le (plus petit) nombre tel que pour toute suite d'arbres T_1,
..., T_f(n), chaque arbre étant étiqueté par un élément dans {1, ..., n},
et l'arbre T_i ayant au plus i sommets, alors il y a forcément deux arbres
T_a et T_b avec T_a <= T_b (ie on peut mapper homéorphiquement T_a dans T_b
en préservant les étiquettes).

Alors je propose f(42), c'est déjà un bon challenge de faire mieux ;)

                                ---
-> yaf.maths:1065

> En tout cas j'ai en tête une approche qui explose complètement les
> deux (et, pour le coup, qui produit un nombre démontrablement
> supérieur à la fois à Ackermann(9999999,9999999) et à TREE(42)).

Bon, voici la solution - enfin, le programme que j'avais en tête :

Je commence par calculer N=10^(10^100) (juste pour bootstraper).
Ensuite, j'énumère toutes les chaînes de caractères de longueur <=N,
et je garde celles qui (1) sont des démonstrations valides dans ZFC,
et (2) ont une conclusion du type « la machine de Turing <truc>
termine » : visiblement, ces critères sont testables et pas
horriblement chiants à programmer.  Je fais une liste de toutes ces
machines de Turing, et je les exécute tour à tour, en mesurant, à
chaque fois, le nombre d'étapes d'exécution.  Je renvoie le max de ces
nombres (bon, ne soyons pas chiche : je renvoie la somme, ou le
produit, mais enfin, à ce stade-là, ça ne change franchement pas
grand-chose).

En une phrase : je renvoie la somme des temps d'exécution des machines
de Turing dont ZFC prouve la terminaison en au plus 10^(10^100)
symboles.

Pourquoi est-ce beaucoup plus grand que Ackermann(9999999,9999999) et
que TREE(42) ?  Parce que la démonstration du fait que les fonctions
d'Ackermann ou TREE sont bien définies (i.e., que les machines de
Turing qui les calculent terminent pour toute entrée) se font sans
difficulté dans ZFC, et manifestement en beaucoup moins que N
symboles.  Donc en instanciant à toute entrée qui s'écrit en beaucoup
moins que N symboles, mon programme va trouver la machine
correspondante et l'exécuter.

Mais mais mais, me dira-t-on, tu ne sais pas si ton programme termine,
puisque tu ne peux pas le démontrer dans ZFC (vu que c'est le point de
départ d'un argument à la Gödel : ZFC ne peut pas prouver que toute
machine de Turing dont ZFC prouve la terminaison termine
effectivement ; et visiblement, sur mon instance précise, ZFC ne peut
pas prouver que mon programme termine en moins de N symboles puisque
sinon le nombre serait supérieur à lui-même).  Et pourtant si !
Puisque toute démonstration faite de longueur <=N ne peut pas utiliser
les axiomes de Pi^k-remplacement pour k>N (puisqu'il sont trop longs
pour tenir dans la démonstration ! - peu importe si vous ne savez pas
exactement ce que Pi^k veut dire, c'est juste une mesure de
complexité), donc en particulier, cette démonstration n'est pas dans
ZFC, elle est dans ZFC où l'axiome de remplacement est limité aux
énoncés Pi^N ou moins.  Or ZFC prouve bien la consistance de ce
sous-système de ZFC, et même sa véracité arithmétique (i.e., que s'il
montre la terminaison d'une machine de Turing alors elle termine
vraiment) : cette démonstration est très très longue (puisqu'on
utilise vraiment N quantificateurs, écrits de façon explicite), mais
produite de façon complètement mécanique à partir de N, et elle figure
dans tous les bons livres de théorie des ensembles.  Donc ZFC prouve
bien (quoique très très laborieusement) que mon programme termine et
que mon grand nombre est bien défini.

Après, si on croit à plus que ZFC, on peut faire beaucoup plus grand :
si je remplace ZFC par ZFC + « il existe un cardinal inaccessible »
(IC), par exemple, mon nombre est beaucoup plus grand que celui pour
ZFC (même en remplaçant N par N^N ou truc de ce genre).  En effet,
ZFC+IC prouve de façon très courte, lui, que mon programme est bien
défini (parce que ZFC+IC prouve que toute machine de Turing dont ZFC
prouve qu'elle termine, termine effectivement) : du coup, le programme
avec ZFC+IC, il trouvera mon programme (avec ZFC) parmi les programmes
dont il énumérera une preuve de terminaison, et évidemment pareil avec
des variantes beaucoup plus grosses de N, donc en remplaçant ZFC par
ZFC+IC on obtient un nombre considérablement plus grand.  Et le même
argument exactement vaut pour tout axiome de grand cardinal, donc on
peut prendre le plus grand auquel on veut bien croire.

-- 
David, qui aime beaucoup ce genre de variations sur un thème de Gödel,
et qui trouve que ça soulève des questions philosophiques un peu
effrayantes.

